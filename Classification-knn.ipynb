{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - KNN\n",
    "\n",
    "Dataset - The Titanic dataset: <br/>\n",
    "<img src=\"images/ships-titanic-vehicles-best.jpg\" Width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file section:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The xInstances contains all columns, besides the 'Survived' column, which is the category column\n",
    "# ----- the xInstances is a dataframe, with the 'PassengerId' column as an index.\n",
    "# ----- the xInstances dataframe contains the instance vectors (each row is an instance with values of the features) \n",
    "# The yCategories contains only two columns: 'PassengerId','Survived' (which is a column of the categories) \n",
    "# ----- the yCategories is a dataframe, with the 'PassengerId' column as an index.\n",
    "# ----- the yCategories dataframe contains only the category column ('Survived'), besides the index \n",
    "# ----- (each value in the 'Survived' column corresponds to the feature vector in xInstances with the same 'PassengerId') \n",
    "# --------------------- \n",
    "def loadCsvFile(fileName):\n",
    "    df_titanic=pd.read_csv(fileName)\n",
    "    xInstances=pd.DataFrame(df_titanic.iloc[:,0:10])\n",
    "    xInstances.set_index('PassengerId',inplace=True)\n",
    "    yCategories=pd.DataFrame(df_titanic,columns=['PassengerId','Survived'])\n",
    "    yCategories.set_index('PassengerId',inplace=True)\n",
    "    return xInstances,yCategories\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic instance dataframe object is NOT empty\n",
      "\t titanic instance dataframe object was loaded successfuly\n",
      "titanic category dataframe object is NOT empty\n",
      "\t titanic category dataframe object was loaded successfuly\n",
      "------------------------\n",
      "\n",
      "instance (=feature vector) datafame (displaying the \"age\",\"gender\" features):\n",
      "              Age  Gender\n",
      "PassengerId              \n",
      "1            22.0    male\n",
      "2            38.0  female\n",
      "3            26.0  female\n",
      "4            35.0  female\n",
      "5            35.0    male\n",
      "------------------------\n",
      "\n",
      "class (=category) datafame:\n",
      "             Survived\n",
      "PassengerId          \n",
      "1                   0\n",
      "2                   1\n",
      "3                   1\n",
      "4                   1\n",
      "5                   0\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xTitanicInstances, yTitanicCategories = loadCsvFile('titanic_dataset_fix.csv')\n",
    "# validating that the data is loaded successfully:\n",
    "assert xTitanicInstances is not None, 'titanic instance dataframe object is empty'\n",
    "print ( 'titanic instance dataframe object is NOT empty')\n",
    "assert 'Survived' not in xTitanicInstances.columns, 'instances should not include the category column'\n",
    "assert np.array_equal(xTitanicInstances['Age'].head().tolist()[1:3],[38, 26]), 'titanic instance dataframe object was NOT loaded successfully'\n",
    "print (\"\\t titanic instance dataframe object was loaded successfuly\")\n",
    "assert yTitanicCategories is not None, 'titanic category dataframe object is empty'\n",
    "assert 'Survived' in yTitanicCategories.columns, 'category dataframe is missing the category column'\n",
    "print ( 'titanic category dataframe object is NOT empty')\n",
    "assert np.array_equal(yTitanicCategories['Survived'].head().tolist()[:2],[0, 1]), 'titanic category dataframe object was NOT loaded successfully'\n",
    "print (\"\\t titanic category dataframe object was loaded successfuly\")\n",
    "print ('------------------------\\n')\n",
    "\n",
    "  \n",
    "print ('instance (=feature vector) datafame (displaying the \"age\",\"gender\" features):')\n",
    "print (xTitanicInstances[['Age','Gender']].head())\n",
    "print ('------------------------\\n')\n",
    "print ('class (=category) datafame:')\n",
    "print (yTitanicCategories.head())\n",
    "print ('------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameter: xInstances - the instance dataframe (=feature vectors) without the categories  \n",
    "# input parameter: yCategories - the category (=class/tag) dataframe\n",
    "# input parameter: testRatio - a 0<number<1, which represent the ratio of the dataset which will be used by the test set\n",
    "# --- as explained, frequently used values are: 0.1, 0.2 or 0.3\n",
    "# output: xTrainInstances, xTestInstances, yTrainCategories, yTestCategories\n",
    "\n",
    "def trainTestSplit(xInstances,yCategories,testRatio):\n",
    "    testCountX=int(xInstances.shape[0]*testRatio)\n",
    "    trainCountX=int(xInstances.shape[0]*(1-testRatio))\n",
    "    isUsed=np.zeros(yCategories.shape[0])\n",
    "    found=0\n",
    "    lsta=[]\n",
    "    lstb=[]\n",
    "    index=randrange(yCategories.shape[0])\n",
    "    for x in range(testCountX):\n",
    "        while found==0:\n",
    "            if isUsed[index]==0:\n",
    "                isUsed[index]+=1\n",
    "                found=1\n",
    "                lsta.append(index)\n",
    "            else:\n",
    "                index=randrange(yCategories.shape[0])\n",
    "        found=0\n",
    "    for y in range(trainCountX):\n",
    "        while found==0:\n",
    "            if isUsed[index]==0:\n",
    "                isUsed[index]+=1\n",
    "                found=1\n",
    "                lstb.append(index)\n",
    "            else:\n",
    "                index=randrange(yCategories.shape[0])\n",
    "        found=0\n",
    "    xTrainInstances=xInstances.iloc[lstb]\n",
    "    yTrainCategories=yCategories.iloc[lstb]\n",
    "    xTestInstances=xInstances.iloc[lsta]\n",
    "    yTestCategories=yCategories.iloc[lsta]\n",
    "    return (xTrainInstances,xTestInstances,yTrainCategories,yTestCategories)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Age  Gender\n",
      "PassengerId                   \n",
      "5            35.000000    male\n",
      "8             2.000000    male\n",
      "7            54.000000    male\n",
      "4            35.000000  female\n",
      "1            22.000000    male\n",
      "6            41.560785    male\n",
      "9            27.000000  female\n",
      "-----------------\n",
      "              Age  Gender\n",
      "PassengerId              \n",
      "3            26.0  female\n",
      "10           14.0  female\n",
      "2            38.0  female\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "xTitanicInstances10 = xTitanicInstances.iloc[:10]\n",
    "yTitanicCategories10= yTitanicCategories.iloc[:10]\n",
    "\n",
    "from random import seed\n",
    "seed(1)\n",
    "splitSize=0.3\n",
    "xTrain,xTest,yTrain,yTest = trainTestSplit(xTitanicInstances10,yTitanicCategories10,splitSize)\n",
    "assert xTest is not None, 'xTest should not be None'\n",
    "assert len(xTest)==len(xTitanicInstances10)*splitSize,'wrong split size'\n",
    "assert yTest is not None, 'yTest should not be None'\n",
    "assert len(yTest)==len(xTitanicInstances10)*splitSize,'wrong split size'\n",
    "assert xTrain is not None, 'xTrain should not be None'\n",
    "assert len(xTrain)==len(xTitanicInstances10)*(1-splitSize),'wrong split size'\n",
    "assert yTrain is not None, 'yTrain should not be None'\n",
    "assert len(yTrain)==len(xTitanicInstances10)*(1-splitSize),'wrong split size'\n",
    "\n",
    "print(xTrain[['Age','Gender']])\n",
    "print('-----------------')\n",
    "print(xTest[['Age','Gender']])\n",
    "print('-----------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xSeriesTestVector and xSeriesTrainVector are actually Series objects\n",
    "# ---- the xSeriesTestVector and xSeriesTrainVector consist of a single row (in the from xTrain and xTest correspondigly) \n",
    "# The xInstances contains all columns, besides the 'Survived' column, which is the category column\n",
    "\n",
    "def euclideanDist(xSeriesTestVector,xSeriesTrainVector):\n",
    "    distance = 0.0\n",
    "    for i in range(len(xSeriesTrainVector)):\n",
    "        distance += ((xSeriesTestVector.iloc[i] - xSeriesTrainVector.iloc[i])**2)\n",
    "    return np.sqrt(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0]\n",
      "[3 3 1]\n",
      "Euclidean Distance calculated successfuly: 2.236068\n"
     ]
    }
   ],
   "source": [
    "inst0 = xTitanicInstances[['Pclass','SibSp','Parch']].iloc[0]\n",
    "inst7 = xTitanicInstances[['Pclass','SibSp','Parch']].iloc[7]\n",
    "print (inst0.values)\n",
    "print (inst7.values)\n",
    "dist = euclideanDist(inst0,inst7)\n",
    "assert float(int(dist*100))/100 == 2.23, 'unexpected euclidean distance'\n",
    "print ('Euclidean Distance calculated successfuly: %f' %(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following function to return the Manhattan Distastance between two vectors from the test and train\n",
    "# xSeriesTestVector and xSeriesTrainVector are actually Series objects\n",
    "# ---- the xSeriesTestVector and xSeriesTrainVector consist of a single row (in the from xTrain and xTest correspondigly) \n",
    "# The xInstances contains all columns, besides the 'Survived' column, which is the category column\n",
    "\n",
    "def manhattanDist(xSeriesTestVector,xSeriesTrainVector): \n",
    "    sum1=xSeriesTestVector-xSeriesTrainVector\n",
    "    res=0\n",
    "    for i in sum1:\n",
    "        res+=abs(i)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0]\n",
      "[3 3 1]\n",
      "Manhattan Distance calculated successfuly: 3\n"
     ]
    }
   ],
   "source": [
    "inst0 = xTitanicInstances[['Pclass','SibSp','Parch']].iloc[0]\n",
    "inst7 = xTitanicInstances[['Pclass','SibSp','Parch']].iloc[7]\n",
    "print (inst0.values)\n",
    "print (inst7.values)\n",
    "dist = manhattanDist(inst0,inst7)\n",
    "assert dist== 3, 'unexpected manhattan distance'\n",
    "print ('Manhattan Distance calculated successfuly: %d' %(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameter - xSeriesTestVector - is a Series object, from the test set\n",
    "# input parameter - xTrainInstances - is a dataframe including all train instances\n",
    "# input parameter - distanceMetric - the name of the distance function, not as a string\n",
    "# ---- distanceMetric - options are: euclideanDist ; manhattanDist\n",
    "# The retuned value is a numpy array, containing distances between the test instance\n",
    "#                 and all train instances (ordered by the train instance order) \n",
    "\n",
    "def calcDistances(xSeriesTestVector, xTrainInstances,distanceMetric):\n",
    "    res=np.zeros(shape=(len(xTrainInstances)))\n",
    "    counter=0\n",
    "    for row in range(len(xTrainInstances)):        \n",
    "        toSend=xTrainInstances.iloc[row]\n",
    "        res[row]=distanceMetric(xSeriesTestVector,toSend)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input parameter - xSeriesTestVector - is a Series object, from the test set\n",
    "# input parameter - xTrainInstances - a dataframe including all train instances\n",
    "# input parameter - yTrainCategories - a dataframe including all train categories \n",
    "# input parameter - distanceMetric - the name of the distance function, not as a string\n",
    "# ---- distanceMetric - options are: euclideanDist ; manhattanDist\n",
    "# input parameter - k - the number of Nearest Neighbors (we select the majority out of k votes)\n",
    "# The retuned value is a numpy array, containing distances between the test instance\n",
    "#                 and all train instances (ordered by the train instance order) \n",
    "\n",
    "def predict(xSeriesTestVector, xTrainInstances,yTrainCategories,distanceMetric,k):\n",
    "    distances = calcDistances(xSeriesTestVector, xTrainInstances,distanceMetric)\n",
    "    toCheck=np.argsort(distances)\n",
    "    checking=np.empty(k)\n",
    "    trueCounter=0\n",
    "    falseCounter=0\n",
    "    Count=np.zeros(abs(len(xSeriesTestVector)-1))\n",
    "    for i in range(k):\n",
    "        if yTrainCategories.iloc[toCheck[i],-1]==1:\n",
    "            trueCounter+=1\n",
    "        else:\n",
    "            falseCounter+=1\n",
    "    if trueCounter>=falseCounter:\n",
    "        category=1\n",
    "    else:\n",
    "        category=0\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhattanDist,k=3, inst=-7, chosen cat: 0\n",
      "euclideanDist,k=3, inst=-7, chosen cat: 1\n",
      "(scaled) manhattanDist,k=3, inst=-7, chosen cat: 1\n",
      "(scaled) euclideanDist,k=3, inst=-7, chosen cat: 1\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "## We will be using standardscaler to transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "xTitanicInstances_5Features = xTitanicInstances[['Pclass','SibSp','Parch','Fare','Age']]\n",
    "xTitanicInstances_5Features_40 = xTitanicInstances_5Features.iloc[:40]\n",
    "yTitanicCategories_40 = yTitanicCategories.iloc[:40]\n",
    "xTitanicInstances_5Features_TestInst = xTitanicInstances_5Features.iloc[-7:-6]\n",
    "## transforming \"train_x\"\n",
    "xTrainScaled = pd.DataFrame(sc.fit_transform(xTitanicInstances_5Features_40),index=xTitanicInstances_5Features_40.index)\n",
    "\n",
    "## transforming \"test_x\"\n",
    "xTestScaled = pd.Series(sc.transform(xTitanicInstances_5Features_TestInst)[0],index=xTitanicInstances_5Features_40.columns)\n",
    "\n",
    "# measure distance without scaling:\n",
    "manhattanDist_k3 = predict(xTitanicInstances_5Features_TestInst.iloc[-1],xTitanicInstances_5Features_40,yTitanicCategories_40,manhattanDist,3)\n",
    "euclideanDist_k3 = predict(xTitanicInstances_5Features_TestInst.iloc[-1],xTitanicInstances_5Features_40,yTitanicCategories_40,euclideanDist,3)\n",
    "assert manhattanDist_k3 == 0,\"wrong value for knn, with k=3, dist='manhattan'\"\n",
    "assert euclideanDist_k3 == 1,\"wrong value for knn, with k=3, dist='euclidean'\"\n",
    "print ('manhattanDist,k=3, inst=-%d, chosen cat: %d' %(7,manhattanDist_k3))\n",
    "print ('euclideanDist,k=3, inst=-%d, chosen cat: %d' %(7,euclideanDist_k3))\n",
    "manhattanDist_scaled_k3 = predict(xTestScaled,xTrainScaled,yTitanicCategories_40,manhattanDist,3)\n",
    "euclideanDist_scaled_k3 = predict(xTestScaled,xTrainScaled,yTitanicCategories_40,euclideanDist,3)\n",
    "# measure distance with scaling:\n",
    "assert manhattanDist_scaled_k3 == 1,\"wrong value for (scaled) knn, with k=3, dist='manhattan'\"\n",
    "assert euclideanDist_scaled_k3 == 1,\"wrong value for (scaled) knn, with k=3, dist='euclidean'\"\n",
    "print ('(scaled) manhattanDist,k=3, inst=-%d, chosen cat: %d' %(7,euclideanDist_scaled_k3))\n",
    "print ('(scaled) euclideanDist,k=3, inst=-%d, chosen cat: %d' %(7,manhattanDist_scaled_k3))\n",
    "print ('---------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(xTestInstances,xTrainInstances,yTrainCategories,yTestCategories,distanceMetric,k):\n",
    "    trueCounter=0\n",
    "    counter=0\n",
    "    x1=pd.Series()\n",
    "    for x in range(len(xTestInstances)):\n",
    "        x1=xTestInstances.iloc[x]\n",
    "        predictedCategory = predict(x1, xTrainInstances, yTrainCategories,distanceMetric,k)\n",
    "        lst=list(xTestInstances.index.values)\n",
    "        toCompar=yTestCategories.loc[lst[x]]\n",
    "        if predictedCategory==toCompar.values:\n",
    "            trueCounter+=1\n",
    "        counter+=1\n",
    "    acc=trueCounter/counter\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhattanDist,k=3, acc: 0.450000\n",
      "(Scaled) euclideanDist,k=3, acc: 0.600000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xTitanicInstances_5Features = xTitanicInstances[['Pclass','SibSp','Parch','Fare','Age']]\n",
    "xTitanicInstances_5Features_100 = xTitanicInstances_5Features.iloc[:100]\n",
    "yTitanicCategories_100 = yTitanicCategories.iloc[:100]\n",
    "xTitanicInstances_5Features_Test_10 = xTitanicInstances_5Features.iloc[-20:]\n",
    "yTitanicCategories_Test_10 = yTitanicCategories.iloc[-20:]\n",
    "## scale:\n",
    "xTrainScaled = pd.DataFrame(sc.fit_transform(xTitanicInstances_5Features_100),index=xTitanicInstances_5Features_100.index)\n",
    "xTestScaled = pd.DataFrame(sc.transform(xTitanicInstances_5Features_Test_10),index=xTitanicInstances_5Features_Test_10.index)\n",
    "\n",
    "acc_manhattan_3 = evaluate_accuracy(xTitanicInstances_5Features_Test_10,xTitanicInstances_5Features_100,yTitanicCategories_100,yTitanicCategories_Test_10,manhattanDist,3)\n",
    "acc_scaled_euclidean_3 = evaluate_accuracy(xTestScaled,xTrainScaled,yTitanicCategories_100,yTitanicCategories_Test_10,euclideanDist,3)\n",
    "\n",
    "assert acc_manhattan_3 == 0.45,\"wrong value for accuracy of knn, with k=3, dist='manhattan'\"\n",
    "assert acc_scaled_euclidean_3 == 0.60,\"wrong value for accuracy of (Scaled) knn, with k=3, dist='euclidean'\"\n",
    "print ('manhattanDist,k=3, acc: %f' %(acc_manhattan_3))\n",
    "print ('(Scaled) euclideanDist,k=3, acc: %f' %(acc_scaled_euclidean_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
